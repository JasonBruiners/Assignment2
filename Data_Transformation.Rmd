---
title: "Data Transformation"
output: html_notebook
---

```{r}
#install_github("mkearney/rtweet")

#Packages
library(usethis)
library(devtools)
library(dplyr)
library(rtweet)
library(readr)
library(topicmodels)
library(tidyverse)
library(maps)
library(tm)
```

## Load extracted data 
```{r}
News24_tweets <- read_rds("Data/Raw_Timeline_Data/News24_tweets.rds")
TimesLIVE_tweets <- read_rds("Data/Raw_Timeline_Data/TimesLIVE_tweets.rds")
eNCA_tweets <- read_rds("Data/Raw_Timeline_Data/eNCA_tweets.rds")
IOL_tweets <- read_rds("Data/Raw_Timeline_Data/IOL_tweets.rds")
SABCNews_tweets <- read_rds("Data/Raw_Timeline_Data/SABCNews_tweets.rds")
ewnupdates_tweets <- read_rds("Data/Raw_Timeline_Data/ewnupdates_tweets.rds")
```

```{r}
tweets_za_13 <- read_rds("Data/Raw_Filtered_Data/tweets_za_13.rds")
tweets_za_14 <- read_rds("Data/Raw_Filtered_Data/tweets_za_14.rds")
tweets_za_15 <- read_rds("Data/Raw_Filtered_Data/tweets_za_15.rds")
tweets_za_16 <- read_rds("Data/Raw_Filtered_Data/tweets_za_16.rds")
tweets_za_17 <- read_rds("Data/Raw_Filtered_Data/tweets_za_17.rds")
tweets_za_18 <- read_rds("Data/Raw_Filtered_Data/tweets_za_18.rds")
#tweets_za_19 <- read_rds("Data/Raw_Filtered_Data/tweets_za_19.rds")
#tweets_za_20 <- read_rds("Data/Raw_Filtered_Data/tweets_za_20.rds")
#tweets_za_21 <- read_rds("Data/Raw_Filtered_Data/tweets_za_21.rds")
```

```{r}
tweets_bloem_13 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_13.rds")
tweets_bloem_14 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_14.rds")
tweets_bloem_15 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_15.rds")
tweets_bloem_16 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_16.rds")
tweets_bloem_17 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_17.rds")
tweets_bloem_18 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_18.rds")
#tweets_bloem_19 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_19.rds")
#tweets_bloem_20 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_20.rds")
#tweets_bloem_21 <- read_rds("Data/Raw_Filtered_Data/tweets_bloem_21.rds")
```

```{r}
tweets_cpt_13 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_13.rds")
tweets_cpt_14 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_14.rds")
tweets_cpt_15 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_15.rds")
tweets_cpt_16 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_16.rds")
tweets_cpt_17 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_17.rds")
tweets_cpt_18 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_18.rds")
#tweets_cpt_19 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_19.rds")
#tweets_cpt_20 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_20.rds")
#tweets_cpt_21 <- read_rds("Data/Raw_Filtered_Data/tweets_cpt_21.rds")
```

```{r}
tweets_durb_13 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_13.rds")
tweets_durb_14 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_14.rds")
tweets_durb_15 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_15.rds")
tweets_durb_16 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_16.rds")
tweets_durb_17 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_17.rds")
tweets_durb_18 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_18.rds")
#tweets_durb_19 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_19.rds")
#tweets_durb_20 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_20.rds")
#tweets_durb_21 <- read_rds("Data/Raw_Filtered_Data/tweets_durb_21.rds")
```

```{r}
tweets_jhb_13 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_13.rds")
tweets_jhb_14 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_14.rds")
tweets_jhb_15 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_15.rds")
tweets_jhb_16 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_16.rds")
tweets_jhb_17 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_17.rds")
tweets_jhb_18 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_18.rds")
#tweets_jhb_19 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_19.rds")
#tweets_jhb_20 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_20.rds")
#tweets_jhb_21 <- read_rds("Data/Raw_Filtered_Data/tweets_jhb_21.rds")
```

```{r}
tweets_kim_13 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_13.rds")
tweets_kim_14 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_14.rds")
tweets_kim_15 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_15.rds")
tweets_kim_16 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_16.rds")
tweets_kim_17 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_17.rds")
tweets_kim_18 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_18.rds")
#tweets_kim_19 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_19.rds")
#tweets_kim_20 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_20.rds")
#tweets_kim_21 <- read_rds("Data/Raw_Filtered_Data/tweets_kim_21.rds")
```

```{r}
tweets_klerk_13 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_13.rds")
tweets_klerk_14 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_14.rds")
tweets_klerk_15 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_15.rds")
tweets_klerk_16 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_16.rds")
tweets_klerk_17 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_17.rds")
tweets_klerk_18 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_18.rds")
#tweets_klerk_19 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_19.rds")
#tweets_klerk_20 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_20.rds")
#tweets_klerk_21 <- read_rds("Data/Raw_Filtered_Data/tweets_klerk_21.rds")
```

```{r}
tweets_mbomb_13 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_13.rds")
tweets_mbomb_14 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_14.rds")
tweets_mbomb_15 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_15.rds")
tweets_mbomb_16 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_16.rds")
tweets_mbomb_17 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_17.rds")
tweets_mbomb_18 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_18.rds")
#tweets_mbomb_19 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_19.rds")
#tweets_mbomb_20 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_20.rds")
#tweets_mbomb_21 <- read_rds("Data/Raw_Filtered_Data/tweets_mbomb_21.rds")
```

```{r}
tweets_polo_13 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_13.rds")
tweets_polo_14 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_14.rds")
tweets_polo_15 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_15.rds")
tweets_polo_16 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_16.rds")
tweets_polo_17 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_17.rds")
tweets_polo_18 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_18.rds")
#tweets_polo_19 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_19.rds")
#tweets_polo_20 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_20.rds")
#tweets_polo_21 <- read_rds("Data/Raw_Filtered_Data/tweets_polo_21.rds")
```

```{r}
tweets_pe_13 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_13.rds")
tweets_pe_14 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_14.rds")
tweets_pe_15 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_15.rds")
tweets_pe_16 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_16.rds")
tweets_pe_17 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_17.rds")
tweets_pe_18 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_18.rds")
#tweets_pe_19 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_19.rds")
#tweets_pe_20 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_20.rds")
#tweets_pe_21 <- read_rds("Data/Raw_Filtered_Data/tweets_pe_21.rds")
```

# Bind Dataframes
```{r}
tweets_za <-rbind(tweets_za_18,tweets_za_17,tweets_za_16,tweets_za_15,tweets_za_14,tweets_za_13)
tweets_bloem <-rbind(tweets_bloem_18,tweets_bloem_17,tweets_bloem_16,tweets_bloem_15,tweets_bloem_14,tweets_bloem_13)
tweets_cpt <-rbind(tweets_cpt_18,tweets_cpt_17,tweets_cpt_16,tweets_cpt_15,tweets_cpt_14,tweets_cpt_13)
tweets_durb <-rbind(tweets_durb_18,tweets_durb_17,tweets_durb_16,tweets_durb_15,tweets_durb_14,tweets_durb_13)
tweets_jhb <-rbind(tweets_jhb_18,tweets_jhb_17,tweets_jhb_16,tweets_jhb_15,tweets_jhb_14,tweets_jhb_13)
tweets_kim <-rbind(tweets_kim_18,tweets_kim_17,tweets_kim_16,tweets_kim_15,tweets_kim_14,tweets_kim_13)
tweets_klerk <-rbind(tweets_klerk_18,tweets_klerk_17,tweets_klerk_16,tweets_klerk_15,tweets_klerk_14,tweets_klerk_13)
tweets_mbomb <-rbind(tweets_mbomb_18,tweets_mbomb_17,tweets_mbomb_16,tweets_mbomb_15,tweets_mbomb_14,tweets_mbomb_13)
tweets_polo <-rbind(tweets_polo_18,tweets_polo_17,tweets_polo_16,tweets_polo_15,tweets_polo_14,tweets_polo_13)
tweets_pe <-rbind(tweets_pe_18,tweets_pe_17,tweets_pe_16,tweets_pe_15,tweets_pe_14,tweets_pe_13)

```

# Performing transformations

## cleaning data (text)
```{r}
#Separate date column
News24_tweets <- separate(News24_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)
timesLIVE_tweets <- separate(TimesLIVE_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)
Ewnupdate_tweets <- separate(ewnupdates_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)
IOL_tweets <- separate(IOL_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)
eNCA_tweets <- separate(eNCA_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)
SABC_tweets <- separate(SABCNews_tweets, created_at, into=c("date","time"), sep=" ") %>% group_by(date) %>% mutate(date = as.Date(date)) %>% select(date, time, text, source, favorite_count, retweet_count)


#Subset data into 3 week range 1 June - 21 June

myfunc <- function(x,y){News24_tweets[News24_tweets$date >= x & News24_tweets$date <= y,]}

DATE1 <- as.Date("2020-06-01")
DATE2 <- as.Date("2020-06-21")

News24_tweets <- myfunc(DATE1,DATE2)
timesLIVE_tweets <- myfunc(DATE1,DATE2)
Ewnupdate_tweets <- myfunc(DATE1,DATE2)
IOL_tweets <- myfunc(DATE1,DATE2)
eNCA_tweets <- myfunc(DATE1,DATE2)
SABC_tweets <- myfunc(DATE1,DATE2)


```


```{r}
# AFFIN Sentiment Analysis
# this example uses 
library(tidytext)
library(textdata)

News24_text<- News24_tweets %>% select(text)

News24_cleaned <- unique(News24_text)
News24_cleaned$stripped_text <- tolower(News24_cleaned$text)

News24_cleaned$stripped_text <- gsub("http[^[:space:]]*", " ", News24_cleaned$stripped_text) # remove links
News24_cleaned$stripped_text <- gsub("@\\S*","", News24_cleaned$stripped_text) # remove mentons
News24_cleaned$stripped_text <- gsub("amp","", News24_cleaned$stripped_text) 
News24_cleaned$stripped_text <- gsub("[\r\n]","", News24_cleaned$stripped_text)
News24_cleaned$stripped_text <- gsub("[[:punct:]]"," ", News24_cleaned$stripped_text) #emove punctuation
News24_cleaned$stripped_text = gsub("[ |\t]{2,}", " ", News24_cleaned$stripped_text) # remove tabs
News24_cleaned$stripped_text = gsub("^ ", "", News24_cleaned$stripped_text) # leading blanks
News24_cleaned$stripped_text = gsub(" $", "", News24_cleaned$stripped_text) #laggin blanks
News24_cleaned$stripped_text = gsub(" +", " ", News24_cleaned$stripped_text) #general spaces

head(News24_cleaned$text)
head(News24_cleaned$stripped_text)

#AFFIN_tweets <- News24_tweets$text %>% inner_join(get_seniments("affin")) %>% count(word, sentiment, sort = TRUE) %>% ungroup()

```

```{r}
# Topic Analysis

# topic modeling using LDA
# example on rpubs.com

corpus <- Corpus(VectorSource(News24_cleaned$text))
dtm = DocumentTermMatrix(corpus)

lda_5 = LDA(dtm, k = 5, method = 'Gibbs', 
          control = list(nstart = 5, seed = list(1505,99,36,56,88), best = TRUE, 
                         thin = 500, burnin = 4000, iter = 2000))

#LDA model with 2 topics selected
lda_2 = LDA(dtm, k = 2, method = 'Gibbs', 
          control = list(nstart = 5, seed = list(1505,99,36,56,88), best = TRUE, 
                         thin = 500, burnin = 4000, iter = 2000))

#LDA model with 10 topics selected
lda_10 = LDA(dtm, k = 10, method = 'Gibbs', 
          control = list(nstart = 5, seed = list(1505,99,36,56,88), best = TRUE, 
                         thin = 500, burnin = 4000, iter = 2000))

# comparing total tweets by medias vs the amount that was related to COVID-19 COULD THIS BE SEEN AS TOPIC ANALYSIS???????
#start
#end
#lda_2
#lda_5
#lda_10
```

```{r}
#Top 10 terms or words under each topic
top10terms_5 = as.matrix(terms(lda_5,10))
top10terms_2 = as.matrix(terms(lda_2,10))
top10terms_10 = as.matrix(terms(lda_10,10))

top10terms_5
top10terms_2
top10terms_10

```

```{r}
#Topics found out by our model:
lda.topics_5 = as.matrix(topics(lda_5))
lda.topics_2 = as.matrix(topics(lda_2))
lda.topics_10 = as.matrix(topics(lda_10))
#write.csv(lda.topics_5,file = paste('LDAGibbs',5,'DocsToTopics.csv'))
#write.csv(lda.topics_2,file = paste('LDAGibbs',2,'DocsToTopics.csv'))
#write.csv(lda.topics_10,file = paste('LDAGibbs',10,'DocsToTopics.csv'))

summary(as.factor(lda.topics_5[,1]))
summary(as.factor(lda.topics_2[,1]))
summary(as.factor(lda.topics_10[,1]))
```


```{r}
#document wise probability of each topic.
topicprob_5 = as.matrix(lda_5@gamma)
topicprob_2 = as.matrix(lda_2@gamma)
topicprob_10 = as.matrix(lda_10@gamma)

#write.csv(topicprob_5, file = paste('LDAGibbs', 5, 'DoctToTopicProb.csv'))
#write.csv(topicprob_2, file = paste('LDAGibbs', 2, 'DoctToTopicProb.csv'))
#write.csv(topicprob_10, file = paste('LDAGibbs', 10, 'DoctToTopicProb.csv'))

head(topicprob_2,1)
```

```{r}

```


```{r}
# Other Analysis

# Frequency of tweets by day
News24_freq <- News24_tweets %>% summarise(News24 = n())
timesLIVE_freq <- timesLIVE_tweets %>% summarise(timesLIVE = n())
Ewnupdate_freq <- Ewnupdate_tweets %>% summarise(Ewnupdate = n())
IOL_freq <- IOL_tweets %>% summarise(IOL = n())
eNCA_freq <- eNCA_tweets %>% summarise(eNCA = n()) 
SABC_freq <- SABC_tweets %>% summarise(SABC = n())

# sum days and join together, then send to visualisation
#Frequency_tweets <- cbind(News24_freq,timesLIVE_freq,Ewnupdate_freq,IOL_freq,eNCA_freq,SABC_freq)

#retweet count 
News24_retweet <- News24_tweets %>% summarise(News24 = sum(retweet_count))
timesLIVE_retweet <- timesLIVE_tweets %>% summarise(timesLIVE = sum(retweet_count))
Ewnupdate_retweet <- Ewnupdate_tweets %>% summarise(Ewnupdate = sum(retweet_count))
IOL_retweet <- IOL_tweets %>% summarise(IOL = sum(retweet_count))
eNCA_retweet <- eNCA_tweets %>% summarise(eNCA = sum(retweet_count)) 
SABC_retweet <- SABC_tweets %>% summarise(SABC = sum(retweet_count))

# sum days and join together, then send to visualisation
#retweet_tweets <- cbind(News24_retweet,timesLIVE_retweet,Ewnupdate_retweet,IOL_retweet,eNCA_retweet,SABC_retweet)

# like count
News24_likes <- News24_tweets %>% summarise(News24 = sum(favorite_count))
timesLIVE_likes <- timesLIVE_tweets %>% summarise(timesLIVE = sum(favorite_count))
Ewnupdate_likes <- Ewnupdate_tweets %>% summarise(Ewnupdate = sum(favorite_count))
IOL_likes <- IOL_tweets %>% summarise(IOL = sum(favorite_count))
eNCA_likes <- eNCA_tweets %>% summarise(eNCA = sum(favorite_count)) 
SABC_likes <- SABC_tweets %>% summarise(SABC = sum(favorite_count))

# sum days and join together, then send to visualisation
#Likes_tweets <- cbind(News24_likes,timesLIVE_likes,Ewnupdate_likes,IOL_likes,eNCA_likes,SABC_likes)


# Comparing likes and retweets i.e maby retweets per like or compaing stats of non-covid to covid
#start
#end

```

```{r}
#count the total number of tweets for each media house
News24_freq <- nrow(News24_freq)
timesLIVE_freq <- nrow(timesLIVE_freq)
Ewnupdate_freq <- nrow(Ewnupdate_freq)
IOL_freq <- nrow(IOL_freq)
eNCA_freq <- nrow(eNCA_freq)
SABC_freq <- nrow(SABC_freq)

News24_freq
timesLIVE_freq
Ewnupdate_freq
IOL_freq
eNCA_freq
SABC_freq
```


## Done

# Exporting transformation results
```{r echo=TRUE}
#write_rds(News24_tweets, "Results/News24_tweets.rds")
#write_rds(TimesLIVE_tweets, "Results/TimesLIVE_tweets.rds")
#write_rds(eNCA_tweets, "Results/eNCA_tweets.rds")
#write_rds(IOL_tweets,"Results/IOL_tweets.rds")
#write_rds(SABCNews_tweets,"Results/SABCNews_tweets.rds")
#write_rds(ewnupdates_tweets,"Results/ewnupdates_tweets")
```

```{r}




```



```

## Exporting results
```{r}

```